<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[请输入密码，查看文章！( 。＿ 。) ✎ ＿ Incorrect Password! No content to display! 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]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy与scrapy-redis]]></title>
    <url>%2F2019%2F09%2F12%2Fscrapy%E4%B8%8Escrapy-redis%2F</url>
    <content type="text"><![CDATA[​ 最近在工作中写了很多 scrapy_redis 分布式爬虫，但是回想 scrapy 与 scrapy_redis 两者区别的时候，竟然，思维只是局限在了应用方面，于是乎，搜索了很多相关文章介绍，这才搞懂内部实现的原理。 首先我们从整体上来讲​ scrapy是一个Python爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。而scrapy-redis一套基于redis数据库、运行在scrapy框架之上的组件，可以让scrapy支持分布式策略，Slaver端共享Master端redis数据库里的item队列、请求队列和请求指纹集合。而为什么选择redis数据库，是因为redis支持主从同步，而且数据都是缓存在内存中的，所以基于redis的分布式爬虫，对请求和数据的高频读取效率非常高。 ​ 有一篇文章是这么说的：scrapy-redis 与 Scrapy的关系就像电脑与固态硬盘一样，是电脑中的一个插件，能让电脑更快的运行。 Scrapy 是一个爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，它可以让爬虫跑的更快。 ​ 说的一点都对，Scrapy 是一个通用的爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，为了更方便地实现Scrapy分布式爬取，而提供了一些以redis为基础的组件(仅有组件)，它可以让爬虫跑的更快。 然后介绍 scrapy 框架的运行流程及原理 ​ scrapy作为一款优秀的爬虫框架，在爬虫方面有这众多的优点。能快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。 为了方便理解，我找到了一张这样的图片： 解释说明：1、从优先级队列中获取request对象，交给engine 2、engine将request对象交给下载器下载，期间会通过downloadmiddleware的process_request方法 3、下载器完成下载，获得response对象，将该对象交给engine，期间会经过downloadmiddleware的process_response（ ）方法 4、engine将获得的response对象交给spider进行解析，期间会经过spidermiddleware的process_spider_input()的方法 5、spider解析下载器下下来的response，返回item或是links(url) 6、item或者link经过spidermiddleware的process_spider_out( )方法，交给engine 7、engine将item交给item pipeline ，将links交给调度器 8、在调度器中，先将requests对象利用scrapy内置的指纹函数生成一个指纹 9、如果requests对象中的don’t filter参数设置为False，并且该requests对象的指纹不在信息指纹的队列中，那么就把该request对象放到优先级队列中 循环以上操作 中间件主要存在两个地方，从图片当中我们可以看到： spider 与 engine 之间（爬虫中间件）： ​ 介于Scrapy引擎和爬虫之间的框架，主要工作是处理爬虫的响应输入和请求输出 download 与 engine 之间（下载器中间件） ： 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应 借此机会，我们结合程序，解析一下框架中的 middleware.py ： Spider Middleware有以下几个函数被管理: process_spider_input 接收一个response对象并处理, 位置是Downloader–&gt;process_spider_input–&gt;Spiders(Downloader和Spiders是scrapy官方结构图中的组件) ​ - process_spider_exception spider出现的异常时被调用 - process_spider_output 当Spider处理response返回result时,该方法被调用 - process_start_requests 当spider发出请求时,被调用 Downloader Middleware有以下几个函数被管理 - process_request request通过下载中间件时，该方法被调用，这里可以设置代理，设置request.meta[‘proxy’] 就行 - process_response 下载结果经过中间件时被此方法处理 - process_exception 下载过程中出现异常时被调用 个人理解scrapy的优缺点：优点：scrapy 是异步的，写middleware,方便写一些统一的过滤器 缺点：基于python的爬虫框架，扩展性比较差，基于twisted框架，运行中的exception是不会干掉reactor，并且异步框架出错后是不会停掉其他任务的，数据出错后难以察觉。 scrapy_redis分布式爬虫最后回到我们这篇文章的重点（敲黑板…） Scrapy-redis提供了下面四种组件（components）：(四种组件意味着这四个模块都要做相应的修改) Scheduler： Scrapy改造了python本来的collection.deque(双向队列)形成了自己的Scrapy queue，但是Scrapy多个spider不能共享待爬取队列Scrapy queue， 即Scrapy本身不支持爬虫分布式，scrapy-redis 的解决是把这个Scrapy queue换成redis数据库（也是指redis队列），从同一个redis-server存放要爬取的request，便能让多个spider去同一个数据库里读取。 Scrapy中跟“待爬队列”直接相关的就是调度器Scheduler，它负责对新的request进行入列操作（加入Scrapy queue），取出下一个要爬取的request（从Scrapy queue中取出）等操作。它把待爬队列按照优先级建立了一个字典结构，然后根据request中的优先级，来决定该入哪个队列，出列时则按优先级较小的优先出列。为了管理这个比较高级的队列字典，Scheduler需要提供一系列的方法。但是原来的Scheduler已经无法使用，所以使用Scrapy-redis的scheduler组件。 Duplication Filter： Scrapy中用集合实现这个request去重功能，Scrapy中把已经发送的request指纹放入到一个集合中，把下一个request的指纹拿到集合中比对，如果该指纹存在于集合中，说明这个request发送过了，如果没有则继续操作。 在scrapy-redis中去重是由Duplication Filter组件来实现的，它通过redis的set 不重复的特性，巧妙的实现了Duplication Filter去重。scrapy-redis调度器从引擎接受request，将request的指纹存⼊redis的set检查是否重复，并将不重复的request push写⼊redis的 request queue。 引擎请求request(Spider发出的）时，调度器从redis的request queue队列⾥里根据优先级pop 出⼀个request 返回给引擎，引擎将此request发给spider处理。 Item Pipeline： 引擎将(Spider返回的)爬取到的Item给Item Pipeline，scrapy-redis 的Item Pipeline将爬取到的 Item 存⼊redis的 items queue。 修改过Item Pipeline可以很方便的根据 key 从 items queue 提取item，从⽽实现items processes集群。 Base Spider： 不在使用scrapy原有的Spider类，重写的RedisSpider继承了Spider和RedisMixin这两个类，RedisMixin是用来从redis读取url的类。 当我们生成一个Spider继承RedisSpider时，调用setup_redis函数，这个函数会去连接redis数据库，然后会设置signals(信号)： 一个是当spider空闲时候的signal，会调用spider_idle函数，这个函数调用schedule_next_request函数，保证spider是一直活着的状态，并且抛出DontCloseSpider异常。一个是当抓到一个item时的signal，会调用item_scraped函数，这个函数会调用schedule_next_request函数，获取下一个request。 Scrapy-redis架构： 如上图所示，我们可以发现，scrapy-redis在scrapy的架构上增加了redis，与scrapy相差无几。本质的区别就是，将scrapy的内置的去重的队列和待抓取的request队列换成了redis的集合。就这一个小小的改动，就使得了scrapy-redis支持了分布式抓取。 Scrapy-Redis分布式策略： 假设有四台电脑：Windows 10、Mac OS X、Ubuntu 16.04、CentOS 7.2，任意一台电脑都可以作为 Master端 或 Slaver端，比如： –Master端(核心服务器) ：使用 Windows 10，搭建一个Redis数据库，不负责爬取，只负责url指纹判重、Request的分配，以及数据的存储–Slaver端(爬虫程序执行端) ：使用 Mac OS X 、Ubuntu 16.04、CentOS 7.2，负责执行爬虫程序，运行过程中提交新的Request给Master 首先Slaver端从Master端拿任务（Request、url）进行数据抓取，Slaver抓取数据的同时，产生新任务的Request便提交给 Master 处理；Master端只有一个Redis数据库，负责将未处理的Request去重和任务分配，将处理后的Request加入待爬队列，并且存储爬取的数据。 明白了原理之后我们就要入手程序了 Scrapy-Redis默认使用的就是这种策略，我们实现起来很简单，因为任务调度等工作Scrapy-Redis都已经帮我们做好了，我们只需要继承RedisSpider、指定redis_key就行了。 将 scrapy 变成 scrapy-redis 的过程（前提是pip install scrapy-redis） 1、修改settings.py文件，最简单的方式是使用redis替换机器内存，你只需要在 settings.py 中加上三代码，就能让你的爬虫变为分布式。 2、配置redis 3、配置如下参数 4、自定义爬虫类继承RedisSpider 如果你现在运行你的爬虫，你可以在redis中看到出现了这两个key: 格式是set，即不会有重复数据。前者就是redis的去重队列，对应DUPEFILTER_CLASS，后者是redis的请求调度，把里面的请求分发给爬虫，对应SCHEDULER。（里面的数据不会自动删除，如果你第二次跑，需要提前清空里面的数据） 备注：虽然scrapy_redis 可以极大的提高爬虫的运行的效率，但也是存在缺点的，Scrapy-Redis调度的任务是Request对象，里面信息量比较大（不仅包含url，还有callback函数、headers等信息），可能导致的结果就是会降低爬虫速度、而且会占用Redis大量的存储空间，所以如果要保证效率，那么就需要一定硬件水平。最后提醒一下大家，并不是所有的网站都可以采用分布式爬虫进行采集，爬虫要追求灵活，所以scrapy-redis并不能代替传统的request爬虫。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本山大叔-念诗之王]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%9C%AC%E5%B1%B1%E5%A4%A7%E5%8F%94-%E5%BF%B5%E8%AF%97%E4%B9%8B%E7%8E%8B%2F</url>
    <content type="text"><![CDATA[中国 Rap 之王]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>鬼畜</tag>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[某科学的超电磁炮]]></title>
    <url>%2F2019%2F08%2F10%2F%E8%B6%85%E7%94%B5%E7%A3%81%E7%82%AE%2F</url>
    <content type="text"><![CDATA[B站剪辑xsjhitokoto() 插件暂时不能使用，忽略......]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建单例]]></title>
    <url>%2F2019%2F08%2F10%2F%E5%88%9B%E5%BB%BA%E5%8D%95%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[使用装饰器： 装饰器不但可以装饰函数，也可以装饰类 如果要书写单例，命名为：defaultInstance，currentInstance，getInstance等 思路：​ 在外部函数中定义一个变量，在内部函数中进行单例的设置，最终将设置的结果返回 方式一1234567891011121314151617181920def singleton(cls): instance = None def getInstance(*args,**kwargs): nonlocal instance #局部变量和全局变量重名，扩大作用域 if not instance: instance = cls(*args,**kwargs) return instance return getInstance@singletonclass Check(): def __init__(self,name,age): self.name = name self.age = agec1 = Check("jack",10)print(c1)c2 = Check("abc",45)print(c2) 方式二123456789101112131415161718192021222324252627282930313233def singleton(cls): #定义一个字典，字典用来保存被装饰的类和对应的唯一的对象,&#123;类:对象&#125; instanceDict = &#123;&#125; def getInstance(*args,**kwargs): if cls not in instanceDict: instanceDict[cls] = cls(*args,**kwargs) return instanceDict[cls] return getInstance@singletonclass Person(object): #实例属性 def __init__(self,name): self.name = name #成员函数 def show(self): pass #类方法 @classmethod def func(cls): pass #静态方法 @staticmethod def func2(): passp1 = Person()print(p1)p2 = Person()print(p2)p1.show()p1.func() 单例类和普通类的区别仅仅是单例类只能创建一个对象，其余的用法和普通类完全相同]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python字符串功能]]></title>
    <url>%2F2019%2F08%2F06%2FPython%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[字符串功能填充.center(width,fillchar)：被填充字符长度只能为 1 .ljust(width,fillchar)：原字符串被居左，其他剩余的字符串使用指定的字符填充，默认使用空格填充 .rjust(width,fillchar)：居右 .zfill(width)：返回一个长度为width的字符串，原字符串右对齐，前面补0 .count((str)[,start],[,end])：返回字符串中str出现的次数，可以指定一个范围，默认从头到尾 查找.find((str)[,start],[,end])：检测str字符串中是否包含在字符串中，可以指定范围，默认从头到尾，得到的是第一次出现的下标，没有找到则返回 -1 .rfind：从右到左 .index()：从列表中获取第一个匹配元素的位置，前提时该元素存在 .rindex()：从右往左 字母转换eval()：可以进行内部数字运算 .lower()：字母全部小写 .upper()：字母全部大写 .swapcase()：字母大转小，小转大 .title()：每个首字母大写 .capitalize()：第一个单词首字母大写 chr(xx) ：char actor ， 字符， 将整数转化为在ASCii码中对应的字符 ord(xx) ：ordinary ，原始的，将资格字符转化为ASCII码中对应的数字 提取.strip：截掉左，右两侧指定字符串，默认为空格 .lstrip：截掉左侧指定字符串，默认为空格 .strip：截掉右侧指定字符串，默认为空格 数字进制转换int(“ “)：将x转化为十进制 int 中的 base 关键字表示按当前需要被转换的数据的形式【什么进制 】，最终通过int返回的是十进制 bin( )：将x转化为二进制hex( )：将x转化为十六进制 cot( )：将x转化为八进制 字符串的分割，列表的合并list = str.split(substr,num)：substr表示分隔符，num表示分割的最大次数 “ substr “.join(列表)：将一个列表中的元素转化为字符串 替换1. 普通替换.replace(old,new,(max))：使用new替换old，可以指定替换最大次数 2. 映射替换（可以进行简单加密）.maketrans(“原始数据”,”需要替换的数据”)：生成一个映射表（ASCII） ！！！生成映射表的时候，两个字符串的长度必须相等，否则报错 .translate()：翻译，通过映射表将指定的字符串中的字符替换]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2和Python3的区别]]></title>
    <url>%2F2019%2F08%2F05%2FPython2%E5%92%8CPython3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1. 性能：py3其实比py2的效率低，py3有极大地优化了空间，效率处于追赶状态2. 编码：py3使用utf-8编码，使得变量名更加广阔【可以使用中文作为变量】3. 语法： ​ 去除了不等于号&lt;&gt;，py3使用的是 != ​ 加入了with…as关键字，新增了None，True，False ​ 加入了nonlocal语句 ​ 去除了print操作符，新增了print()函数 ​ 去除了raw_input操作符，加入了input()函数 ​ 新的super()函数，可以不用传参 ​ 新的八进制的字面量：py2中使用数字0表示八进制，py3中使用0o表示八进制 4. 字符和字符串​ py2中采用8-bit字符串存储，py3中采用16-bit，Unicode字符串存储 ​ py3中不管时一个字符，还是多个字符，都是字符串表示 5. 数据类型​ py2中数字类型分为int和long(长整型) ​ py3中数字类型只有一种int，新增了一种bytes【实现了字符串的编码encode和解码decode】 6. 异常​ py2中：try…except 错误表示码,变量 ​ py3中：try…except 错误表示码 as 变量： 7. 其他​ 1. py2中求变量使用xrange()，py3中使用range() ​ 2. 打开文件： ​ py2中打开文件需要两步：1.file(path) 2.poen(path) ​ py3中打开文件只需要一步：open(path)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构化查询语言]]></title>
    <url>%2F2019%2F08%2F04%2F2019-08-04%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[一：数据查询语言（DQL:Data Query Language）：​ 其语句，也称为“数据检索语句”，用以从表中获得数据，确定数据怎样在应用程序给出。保留字SELECT是DQL（也是所有SQL）用得最多的动词，其他DQL常用的保留字有WHERE，ORDER BY，GROUP BY和HAVING。这些DQL保留字常与其他类型的SQL语句一起使用。 二：数据操作语言（DML：Data Manipulation Language）：​ 其语句包括动词INSERT，UPDATE和DELETE。它们分别用于添加，修改和删除表中的行。也称为动作查询语言。 三：事务处理语言（TPL）：​ 它的语句能确保被DML语句影响的表的所有行及时得以更新。TPL语句包括BEGIN TRANSACTION，COMMIT和ROLLBACK。 四：数据控制语言（DCL）：​ 它的语句通过GRANT或REVOKE获得许可，确定单个用户和用户组对数据库对象的访问。某些RDBMS可用GRANT或REVOKE控制对表单个列的访问。 五：数据定义语言（DDL）：​ 其语句包括动词CREATE和DROP。在数据库中创建新表或删除表（CREAT TABLE 或 DROP TABLE）；为表加入索引等。DDL包括许多与人数据库目录中获得数据有关的保留字。它也是动作查询的一部分。 六：指针控制语言（CCL）：​ 它的语句，像DECLARE CURSOR，FETCH INTO和UPDATE WHERE CURRENT用于对一个或多个表单独行的操作。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
