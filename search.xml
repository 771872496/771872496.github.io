<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[请输入密码，查看文章！( 。＿ 。) ✎ ＿ Incorrect Password! No content to display! U2FsdGVkX1+TJ0xptIjfLatGgQN6bYEpkw6blurm8LN0HiUv9P3SfS/74APnlO/DNc7BrZu5Z7wNyUDCJbyfijD5MLpuCtVIOBZs9pO+6F3uB+x3b0N7FAh06BrRnc/J1rppe1tfmQxILZLm08lsbBvN//ztZ+att+bfiozTer6avzLNRzTUhw1xoYzh9SQhxBo72VMIIXx63BOc0HUnSQEvrV/gVm1zvFNYXy6t7iaMVoqBxEuFRN7BfHb9XDkKSSpBZcc7sKy0rDy2bSS/uGyXenduPM0rOHYyBlB3Hq5S/TaKQshIDGOf15FZmQgsUMckxhBwtL91US7eX2q4ElVSDSDilYTgZ6OoJkoFYu0kyx4LcpncWXw3zSPsFms3jFr1Mu55+BoLIxnT8bkjRvFTPu/0jJh5qFGAq6tb9vwHLCXoqOhThnmtSsfeex4/R8PajIQ9bVDMD1bFZvbtzTf1GHKuMgWDBb2C5LphJ+sFLcp5ATCNtsk7XDWbKKATObpnXd1ZwOWvGMoteg4EGp8JlLH2Q9HivNDLaXr56rs4usl5Ixo0oGEXiI9b64JaKdUnsWnRXe19/1uGliHaLE3PocNR30CCmzNKZezZHSEOiYyEKCL0Efgjo26QlaC7QqA2rkOXodXt6f77TtPPW8JbP7PEx3vCpvojtpi+TR1QICwSHfqayajZ2b/u4gW+8X/uCcCEQIi6WD/8hqlkpW2F3AWcjpZc4WxueIN62DhsWIqr+xFREZ8HX/HacemPw9uTGFy5FGBwFViWI86SMnjcdVZaBvXyUqFxOiBzIiMwIIZFkJqhkB6Fb4KyjIql2O9SLyZhtgRdzDLB4rYHsYbsM7SXjmGz4p/kFsJEilwnSwf1Nu7fv9m0l8mBZ7btx47/i3QcI2/bOVZbxkq0Jas3LMq8rDYo09XBqzXfnIKKZoFR98lbfS0jgs/eNNbNpKcZrCHeXflsJyp642WNCBevoM+c4FjMkl9k35UAM1fUzn3Q/RAjb0EpOEsYXnxGFK3GT8BaV1HrwtKZtkMXbSuXx1ZRMVpl1tjNuOQh9vt9UqGG1n3n8gGuwhWWwTRfs1SpIOoHt1E/tW+vsKfv5ZmwwQSogaMHBPmpeiF/bdn5Z+BwcLSKyZOtWdSfvrWuAzVrvFps7frumc7O1MRmCjdoNOwKg5LxlUnni0GdORMx18hVSY1bH9109eF1tbRHyPdHUcS1A2upzK6v7lnC2H/ijnP01Z4FmrkEdRKJmi+RMkoXWdZD99riNpMBuKQcFsHC6763/gx0mikvYhTqPyL9qU7Feu7eOe2uQ1AYibd8Mm6hEPtwIsqUL6UazFXdV2QE+CYJlVEaCnIy7BC2fyRPULZQQuQ1JtiIrH5MwHIivdWZeKGpNvJIm04Cn+gGenXrXpKrzWZH0ThN7NTIUBsqXJdIxBwouB1NNaGbhJ7iV2iSxe0cV6CrR/Ki9BK+FObhy3EeZaRteVLLmMqXmg3rcZNEE0X4HS4jBeLZsm30RwJau1F1z2nsr6+ip6qJIj/0AjIQ7R4mfGqEKAPLUtegTVdYHxGxgB5rXVPFSdUpAQJknQoWrP9X1j5SQv0hFqOT1YUhksE2XkO9sNfiWG47jO4+/hEzRlzPZ2rbVAWS+A87ZtbOgrspcrX7/L6gGyQiJE7QYfP0Ahlq0dYUnA3D8l8mYaYo6/BKBJqzJTFr/uJF77sayjUI3yc0u2HF+gIFfNfHoiAf5USV5Bvv5KnQGE6ekEaE3/ApeEl/TdpZobvTwcZX+CRVfgQOBMrbbh8FT2TDmMSucw/zmboXipoLyNKMMw2qL0/WyTXSQye5hYaBR5rsNAqWhEmTYwMRKUltBp/IcxGUEN7GfqH8rjRp/gqPDpkemnu2d7jgWH7gtYrJeO/jIKaHhMg1fI5G2j12ls79bPESQzJ2niimsHKoxfOEyayrQmbLelinmoT2HJ0NBaskGc4rbf8yeHd2IbokpebOwytIvY+JQFoFz+s8uGOdqlyes5iXArwwEJbCOXwd7uEiN9kk7yocv4xOSbxqxQ15JPu/C+i7aLkAwGfBLvY66SMw84bMA5rIQI8dn886VROh6DfDcKLv6dV8M0nQDQ737QIn6koTwXwvnbOGYbgoOq+MVZzUD270owEO2nYWJrT2ZSFDtSYzuYEWgUv4nEEtj/D+dwJNUubKLUaH/3/YhlTLhqot08aQHDbEW+/UGT6Dr69aPxs0R/Q1md3s5QJPZntNSZ159n2OjDTMbIFI2Im1kzyKn3mY911r4VAdq1D63umEXJjWDoKY4fNjRnI6LNDXkdZt+QqX8tUGU937NexYFy9kfyS4ki+5j+6TqPWi5sOxVpTu5Zekaf1Q8BrTQZhEijvUkXpBnt6fY8eqgP8/wOnEhRdtBqif56G5oSxS+RMebL2wKU2VtD4gMJAL+e4BB3B58aeBdnyoEnVnxsmRm1n4vCBfCZtRVf9t98d8G150m/h+H0zWc8OFh9ehlVRM3XdZyayI9Gz/HBXoRwkNSVuq0163qxw/6KRNyPIJp0/Hh4YTI/dvAYH687/xQWZBt3h2W0akPhGJmm7GBccsClhsMBn7+OZr9kI0vYzGWGFx1XKLaDwulV9ZnfeECRUocLLBAS1DQpyGKjt3Ww+5Ip9xoYgdRxyy/2tZnuqVmNb6JhC8iP9ErJ52bxOEHD8XP3Ghmzvs6GTAOadrZ/qHbPg78NdHbTPFsrPzNJF4DNj0g9xbRi3YvBsqJf3uielVNZJVbCDb68wuon6ZznL45BRedm3PzNPKL8/BeyJ5VgQyVuwAU6T6BmObE/LUm+1HTytESZowiCiDI+hDOW82Hx1MEgD0mVVogaScdyEtSM2jjR1UwQI/EALa1lMGr+csgeUgp5u6FOoEU7cqq8X/QURsxcjCZvEefMp5maEB/kj2BXDiIfxW0FHYjp/aEv1ry2HAb+qMWebaqJcQV3o+IJL93T37yJERbcBnSyzkSNGuoUkxISkuG3qbJNRMkmSkFIr5CypSbiDU0AJGJ05dG/NRWf+WBJc7QKxyH83XtXKhapTPPfSVl/+H+xEFQtcFZ9FssDnehPzqlLKYB3EkyBWD8kgcvOUWoLdLWSvaxxwQQGlkSJfMaWevvfB1ycJJKLIhHeaJvajJqgXwHflHjsrxPr2vlU1ioC4yKLlDqOu8n0ildE/yf801HoKJrpyDCW0VsJ7k7SKqxro5BUkVnvXtITtifaTshROAvPYPCc3Rrth6+6wx0yl4usjFZqcrD8RVYqqzHb8DdYEa8RW0i9yAlTLqPiVqD9u6vlQZyFB//N8Jnv2aUCFhaYTzqhYtuxlk6zmkPezfsfkm5zO6bgAEV9H+5yfXf2oMEQL25AvdwEwJhTvcSQa100sGDtgqxwJli2DKG++RSJGzPeoix/F9/Y60yo35OC9pCPXfM/rGU0sOixyhoGC1rSFTqGZSszMkNMYfHPaaFflmndtxdu8Gop4c5bL9iMwAzr5iaQd21ItbJ77JCQuD0+4uc465P2v5YdKDNcBt9XRavpD3E2vARiYT+MGBe+22vQUUAuS7vx+XRAx2xr1oKNqqOrEfLnI9GxMPsxZ4mYXv+Yeyj3aNO/YafvzACAyhHEZp5jMNWD+VTKb60JnFjNLjB5+r6S7Vz0pOCUumQDKR26YLonUKTINwPRWaaQmw3fjQxzUTqja3YerJnR16JpBODf1ZiuPX1OfzXP1+RJuCxLAt5nZWBG6+jv6rpINZ9O8XULjJTF5AE9AL0ne/DDv2eCJMwk8KRjfx4MsLOZZarQPxmuV2TNguh5sEzbnDKMIKN6W2lxA+IOi3nXVc/PfMey2Sbp1a7CcSDjhgeGZpg2b+/evK2QiuMkTFnXSaieEsCQtCaJA+tOxvYsS8WI6O0DnYm1/U3gufLPeZL64zBKDvc5NAjuJwaIcyPK/JvG6VhfKoPLLz5VonuSzErf9pfEGh2v72QvtSUUqZQjHEkF7X/nHk5VpZT3t2vNJ0Am0wGIB5pbZea4tCu13WEPftBjMjjPhPId01KjFhTWAPdRX1lDq1iqDSL1TVawO7lhtZHkrjBHp2+l8jZHisKr6cPKDVkqeI8fS9W9hAXT7JxHAqjn7P/GMeIdc0ONhgx01l1ymI6ZDJoKx7I7hIo36Y7jwIViz6i3B29gp5G+RTpnhTsfhPoJZsbgHjBwuP9hMdfnA8gxGvWU9h1YpIMW8JsR+isao/iVV2AhcOckw8YllVuPzomeUhEZxaewjskNACOXy+yuj5lW5ewdYHjTBGGB6Nd4IDd3ZhirjXmrBPn86EQNZaHGt7nCBG+Y5csxtdm631Y15Lnmj+5VvMnrrMx7kFHS6gVQAayZqSjZq+hBX9/dVI/UMNVi6PTcaCE5ea5dWxuKhbQcrcjEENcZ1I2mH0fSs1PMyX1RCLNjzUMM80OfCvw8ZezC4HxxSbkh/nBM7Y5OCiPeJwifoftMq1ZnjsmF0IBkoyGlrxvZvb+/gksrUxTqZ8r/zAImUYhgMMMhauLubXMZAUT797liy0ZIbDCpfgurpQ7CFaSW38sS4q3TucCcrff6AxE3KTTTEVCMeG6tHfvjwUUuCjhyIXclanB6L7CzfHVEfmkO0TOmKFRSGinVr68gIyCwpOZ1waiZddNdXWdDawxqCCPpo2f9i4IqiprPlU9tBKZ5gYQCTfWJFCNSIX5gmVanKIyRJw2c0zmgclcO/hJgARnjNplgG1KKdWk10r1Z0/9ZnFL3WvvItUkQCwi6mj0vzIWwShiSJR5OXSla/oNmfxIHRLZ4hbQnFSnsbZ3HpfUnbGksG8Ey0po9BD3lTgotuG37X4BYjYmm0b45MLjXKNyy/vlY6qMFM6iamLaXywrPcOWK6m8EE3EFcINrbUKdgBbXtv1rGDwRYoVozFSD7J9pJO6pgxIEXlI+bARXPg0bb/CzEZCfvFyYVAkSm35iSfxb0JPcgI/nKMThnKCEMKCkAsvpYFfgQxQM5b6WMMuB7SP5PyNqNaC5WOMXWZBkzmdJVhkA2gFP+ygDf1qALMDwewd7kzNWNrFZxWxUdJFuzXmxxbuA1BtU+InMP9xMOwOcxsdrnaWuKgXQdFnRttlO4wkS9mT7ODITFvFGNQ6Bq4t4XLMSaTeVhYkxmH/B7RzMQdNj7Iy5TOpDLMPoLDpJOxOgJVcLqCEHQvlNdyPVd/YJvWiqAyFFS350MkYzpAWLhjEwbMwnlIQp13QnhzK1LB5zBFJY7pKqnFoM26OxETdhkN58HJS7dBipNN0nUp3J1O18NXzf0972wLPCURzHJxN0DVr/QF4MbRA0FGVei6PvqZl97mMlco8RyV4An3Bn9IdQYY/hESDTYe6WeZEDnChmV2DVP91HDv81z5ucMmIRq3tPaAO3JFKpBda8CMstbKRF2QhXAlrTzBGKlb6lnaSgHnILCZ8h+X1uWcCJA1PifVgCydGU3fVif8PYyb7pjuW1NAXJKfidddKOlzc4PPA7rbxM+vgWKgzdkxIn6FWRkUgSrqROBx7pqxpmktwi1mpmzdUXbvua9uI4tN2BUpe26s8xG7a/5M7vXBeBv6Av08U58HcG6+a5ZjE85DAimGfJT2y/hAEmNWCRdZfnOMXR9wfypN2D6rll/T5W2I6MqqKj87YyjVc2+Yj3gMP5uJqov6h1jDwoPE8okK5MbbLA/RczzUXFCUgr25CCN8wqEoCx2/agejF4pH5oERAQOF7mxl9q8Q17yDZHnvFyhRwM4SluagQIp0zGJe2hwCQnyK3hq5FtTm76iZE+4PNO54knKieWZU9GoIny22AwmEwkZtb5yR25wSW0wfSFPAYVUbUBof8gxjDR35AXzslnokZ3CI9WFWJzWxPmrLQZO4uLxIV1b2glt3JTJ3OdqXJQgDSSa4go70pPQDmv6uRX917VhlcuD68WLOcLKCdeSbzZOW8AUt1yxb4QSm9vbAOP63IVf7Q4NqcZL0c9oqXEoui2eKwSufKkkEurMM/U9zAYolqlNThZKyOSrwF36ENDAvegrc82o9vXuvQbFwoMOCpC1m1G8/RaV4KOu9pFGEeB3KCfdC7HJbszHBY+aZwNQREAsgJn0YHbrZWWfLfA4awUryl3gB0doU+/hFLbYw9n8Sev8RV7ig5JqE7YvvN5w70Mg8tFy6AVX4VHx7ffqY8d6wNqMAztiiCRoylICKhPi+YH78M0ufyUP/VxKvPVLlZV90T+E6SoqdkK/iSnPkNaF2E9zscRY72uaK/0YUYyNYdGqgCFtunIJDmqtQuE7LvBS4HbsxeQCzbc0SR80ttZHMS8XV0O1wJummTUVygzpLljL+JddcV1zM3ItS9SGpj+x1Mn4o5MYVRM8LpEDbLxNYrcvnm5Br58Y1GHW+Fv2CDdQnfY5b5taPhNn6oOkif8LBvaV8vM/CugwEY4k4v/UfAJ8vtFNQ05RWOKG0h4GVXa1pIH6XEUXMBHZx9ErUhDz6R27pIKIY1fCx04gsSq9i0bMSuqMpIYLocB0XzS3dwnX2BoSgKHpLYINLITZsX8F1xP93Y8XWSqH2W0Y3ogPD+ErDV4ZS5aoBvmHR2CATn8pGLiBXjlVfuN4XASR2TUa+Kh9nkJRUQjE1BB7d6yz4TerEkqJk]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy与scrapy-redis]]></title>
    <url>%2F2019%2F09%2F12%2Fscrapy%E4%B8%8Escrapy-redis%2F</url>
    <content type="text"><![CDATA[​ 最近在工作中写了很多 scrapy_redis 分布式爬虫，但是回想 scrapy 与 scrapy_redis 两者区别的时候，竟然，思维只是局限在了应用方面，于是乎，搜索了很多相关文章介绍，这才搞懂内部实现的原理。 首先我们从整体上来讲​ scrapy是一个Python爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。而scrapy-redis一套基于redis数据库、运行在scrapy框架之上的组件，可以让scrapy支持分布式策略，Slaver端共享Master端redis数据库里的item队列、请求队列和请求指纹集合。而为什么选择redis数据库，是因为redis支持主从同步，而且数据都是缓存在内存中的，所以基于redis的分布式爬虫，对请求和数据的高频读取效率非常高。 ​ 有一篇文章是这么说的：scrapy-redis 与 Scrapy的关系就像电脑与固态硬盘一样，是电脑中的一个插件，能让电脑更快的运行。 Scrapy 是一个爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，它可以让爬虫跑的更快。 ​ 说的一点都对，Scrapy 是一个通用的爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，为了更方便地实现Scrapy分布式爬取，而提供了一些以redis为基础的组件(仅有组件)，它可以让爬虫跑的更快。 然后介绍 scrapy 框架的运行流程及原理 ​ scrapy作为一款优秀的爬虫框架，在爬虫方面有这众多的优点。能快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。 为了方便理解，我找到了一张这样的图片： 解释说明：1、从优先级队列中获取request对象，交给engine 2、engine将request对象交给下载器下载，期间会通过downloadmiddleware的process_request方法 3、下载器完成下载，获得response对象，将该对象交给engine，期间会经过downloadmiddleware的process_response（ ）方法 4、engine将获得的response对象交给spider进行解析，期间会经过spidermiddleware的process_spider_input()的方法 5、spider解析下载器下下来的response，返回item或是links(url) 6、item或者link经过spidermiddleware的process_spider_out( )方法，交给engine 7、engine将item交给item pipeline ，将links交给调度器 8、在调度器中，先将requests对象利用scrapy内置的指纹函数生成一个指纹 9、如果requests对象中的don’t filter参数设置为False，并且该requests对象的指纹不在信息指纹的队列中，那么就把该request对象放到优先级队列中 循环以上操作 中间件主要存在两个地方，从图片当中我们可以看到： spider 与 engine 之间（爬虫中间件）： ​ 介于Scrapy引擎和爬虫之间的框架，主要工作是处理爬虫的响应输入和请求输出 download 与 engine 之间（下载器中间件） ： 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应 借此机会，我们结合程序，解析一下框架中的 middleware.py ： Spider Middleware有以下几个函数被管理: process_spider_input 接收一个response对象并处理, 位置是Downloader–&gt;process_spider_input–&gt;Spiders(Downloader和Spiders是scrapy官方结构图中的组件) ​ - process_spider_exception spider出现的异常时被调用 - process_spider_output 当Spider处理response返回result时,该方法被调用 - process_start_requests 当spider发出请求时,被调用 Downloader Middleware有以下几个函数被管理 - process_request request通过下载中间件时，该方法被调用，这里可以设置代理，设置request.meta[‘proxy’] 就行 - process_response 下载结果经过中间件时被此方法处理 - process_exception 下载过程中出现异常时被调用 个人理解scrapy的优缺点：优点：scrapy 是异步的，写middleware,方便写一些统一的过滤器 缺点：基于python的爬虫框架，扩展性比较差，基于twisted框架，运行中的exception是不会干掉reactor，并且异步框架出错后是不会停掉其他任务的，数据出错后难以察觉。 scrapy_redis分布式爬虫最后回到我们这篇文章的重点（敲黑板…） Scrapy-redis提供了下面四种组件（components）：(四种组件意味着这四个模块都要做相应的修改) Scheduler： Scrapy改造了python本来的collection.deque(双向队列)形成了自己的Scrapy queue，但是Scrapy多个spider不能共享待爬取队列Scrapy queue， 即Scrapy本身不支持爬虫分布式，scrapy-redis 的解决是把这个Scrapy queue换成redis数据库（也是指redis队列），从同一个redis-server存放要爬取的request，便能让多个spider去同一个数据库里读取。 Scrapy中跟“待爬队列”直接相关的就是调度器Scheduler，它负责对新的request进行入列操作（加入Scrapy queue），取出下一个要爬取的request（从Scrapy queue中取出）等操作。它把待爬队列按照优先级建立了一个字典结构，然后根据request中的优先级，来决定该入哪个队列，出列时则按优先级较小的优先出列。为了管理这个比较高级的队列字典，Scheduler需要提供一系列的方法。但是原来的Scheduler已经无法使用，所以使用Scrapy-redis的scheduler组件。 Duplication Filter： Scrapy中用集合实现这个request去重功能，Scrapy中把已经发送的request指纹放入到一个集合中，把下一个request的指纹拿到集合中比对，如果该指纹存在于集合中，说明这个request发送过了，如果没有则继续操作。 在scrapy-redis中去重是由Duplication Filter组件来实现的，它通过redis的set 不重复的特性，巧妙的实现了Duplication Filter去重。scrapy-redis调度器从引擎接受request，将request的指纹存⼊redis的set检查是否重复，并将不重复的request push写⼊redis的 request queue。 引擎请求request(Spider发出的）时，调度器从redis的request queue队列⾥里根据优先级pop 出⼀个request 返回给引擎，引擎将此request发给spider处理。 Item Pipeline： 引擎将(Spider返回的)爬取到的Item给Item Pipeline，scrapy-redis 的Item Pipeline将爬取到的 Item 存⼊redis的 items queue。 修改过Item Pipeline可以很方便的根据 key 从 items queue 提取item，从⽽实现items processes集群。 Base Spider： 不在使用scrapy原有的Spider类，重写的RedisSpider继承了Spider和RedisMixin这两个类，RedisMixin是用来从redis读取url的类。 当我们生成一个Spider继承RedisSpider时，调用setup_redis函数，这个函数会去连接redis数据库，然后会设置signals(信号)： 一个是当spider空闲时候的signal，会调用spider_idle函数，这个函数调用schedule_next_request函数，保证spider是一直活着的状态，并且抛出DontCloseSpider异常。一个是当抓到一个item时的signal，会调用item_scraped函数，这个函数会调用schedule_next_request函数，获取下一个request。 Scrapy-redis架构： 如上图所示，我们可以发现，scrapy-redis在scrapy的架构上增加了redis，与scrapy相差无几。本质的区别就是，将scrapy的内置的去重的队列和待抓取的request队列换成了redis的集合。就这一个小小的改动，就使得了scrapy-redis支持了分布式抓取。 Scrapy-Redis分布式策略： 假设有四台电脑：Windows 10、Mac OS X、Ubuntu 16.04、CentOS 7.2，任意一台电脑都可以作为 Master端 或 Slaver端，比如： –Master端(核心服务器) ：使用 Windows 10，搭建一个Redis数据库，不负责爬取，只负责url指纹判重、Request的分配，以及数据的存储–Slaver端(爬虫程序执行端) ：使用 Mac OS X 、Ubuntu 16.04、CentOS 7.2，负责执行爬虫程序，运行过程中提交新的Request给Master 首先Slaver端从Master端拿任务（Request、url）进行数据抓取，Slaver抓取数据的同时，产生新任务的Request便提交给 Master 处理；Master端只有一个Redis数据库，负责将未处理的Request去重和任务分配，将处理后的Request加入待爬队列，并且存储爬取的数据。 明白了原理之后我们就要入手程序了 Scrapy-Redis默认使用的就是这种策略，我们实现起来很简单，因为任务调度等工作Scrapy-Redis都已经帮我们做好了，我们只需要继承RedisSpider、指定redis_key就行了。 将 scrapy 变成 scrapy-redis 的过程（前提是pip install scrapy-redis） 1、修改settings.py文件，最简单的方式是使用redis替换机器内存，你只需要在 settings.py 中加上三代码，就能让你的爬虫变为分布式。 2、配置redis 3、配置如下参数 4、自定义爬虫类继承RedisSpider 如果你现在运行你的爬虫，你可以在redis中看到出现了这两个key: 格式是set，即不会有重复数据。前者就是redis的去重队列，对应DUPEFILTER_CLASS，后者是redis的请求调度，把里面的请求分发给爬虫，对应SCHEDULER。（里面的数据不会自动删除，如果你第二次跑，需要提前清空里面的数据） 备注：虽然scrapy_redis 可以极大的提高爬虫的运行的效率，但也是存在缺点的，Scrapy-Redis调度的任务是Request对象，里面信息量比较大（不仅包含url，还有callback函数、headers等信息），可能导致的结果就是会降低爬虫速度、而且会占用Redis大量的存储空间，所以如果要保证效率，那么就需要一定硬件水平。最后提醒一下大家，并不是所有的网站都可以采用分布式爬虫进行采集，爬虫要追求灵活，所以scrapy-redis并不能代替传统的request爬虫。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本山大叔-念诗之王]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%9C%AC%E5%B1%B1%E5%A4%A7%E5%8F%94-%E5%BF%B5%E8%AF%97%E4%B9%8B%E7%8E%8B%2F</url>
    <content type="text"><![CDATA[中国 Rap 之王]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>鬼畜</tag>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[某科学的超电磁炮]]></title>
    <url>%2F2019%2F08%2F10%2F%E8%B6%85%E7%94%B5%E7%A3%81%E7%82%AE%2F</url>
    <content type="text"><![CDATA[B站剪辑xsjhitokoto() 插件暂时不能使用，忽略......]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建单例]]></title>
    <url>%2F2019%2F08%2F10%2F%E5%88%9B%E5%BB%BA%E5%8D%95%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[使用装饰器： 装饰器不但可以装饰函数，也可以装饰类 如果要书写单例，命名为：defaultInstance，currentInstance，getInstance等 思路：​ 在外部函数中定义一个变量，在内部函数中进行单例的设置，最终将设置的结果返回 方式一1234567891011121314151617181920def singleton(cls): instance = None def getInstance(*args,**kwargs): nonlocal instance #局部变量和全局变量重名，扩大作用域 if not instance: instance = cls(*args,**kwargs) return instance return getInstance@singletonclass Check(): def __init__(self,name,age): self.name = name self.age = agec1 = Check("jack",10)print(c1)c2 = Check("abc",45)print(c2) 方式二123456789101112131415161718192021222324252627282930313233def singleton(cls): #定义一个字典，字典用来保存被装饰的类和对应的唯一的对象,&#123;类:对象&#125; instanceDict = &#123;&#125; def getInstance(*args,**kwargs): if cls not in instanceDict: instanceDict[cls] = cls(*args,**kwargs) return instanceDict[cls] return getInstance@singletonclass Person(object): #实例属性 def __init__(self,name): self.name = name #成员函数 def show(self): pass #类方法 @classmethod def func(cls): pass #静态方法 @staticmethod def func2(): passp1 = Person()print(p1)p2 = Person()print(p2)p1.show()p1.func() 单例类和普通类的区别仅仅是单例类只能创建一个对象，其余的用法和普通类完全相同]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python字符串功能]]></title>
    <url>%2F2019%2F08%2F06%2FPython%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[字符串功能填充.center(width,fillchar)：被填充字符长度只能为 1 .ljust(width,fillchar)：原字符串被居左，其他剩余的字符串使用指定的字符填充，默认使用空格填充 .rjust(width,fillchar)：居右 .zfill(width)：返回一个长度为width的字符串，原字符串右对齐，前面补0 .count((str)[,start],[,end])：返回字符串中str出现的次数，可以指定一个范围，默认从头到尾 查找.find((str)[,start],[,end])：检测str字符串中是否包含在字符串中，可以指定范围，默认从头到尾，得到的是第一次出现的下标，没有找到则返回 -1 .rfind：从右到左 .index()：从列表中获取第一个匹配元素的位置，前提时该元素存在 .rindex()：从右往左 字母转换eval()：可以进行内部数字运算 .lower()：字母全部小写 .upper()：字母全部大写 .swapcase()：字母大转小，小转大 .title()：每个首字母大写 .capitalize()：第一个单词首字母大写 chr(xx) ：char actor ， 字符， 将整数转化为在ASCii码中对应的字符 ord(xx) ：ordinary ，原始的，将资格字符转化为ASCII码中对应的数字 提取.strip：截掉左，右两侧指定字符串，默认为空格 .lstrip：截掉左侧指定字符串，默认为空格 .strip：截掉右侧指定字符串，默认为空格 数字进制转换int(“ “)：将x转化为十进制 int 中的 base 关键字表示按当前需要被转换的数据的形式【什么进制 】，最终通过int返回的是十进制 bin( )：将x转化为二进制hex( )：将x转化为十六进制 cot( )：将x转化为八进制 字符串的分割，列表的合并list = str.split(substr,num)：substr表示分隔符，num表示分割的最大次数 “ substr “.join(列表)：将一个列表中的元素转化为字符串 替换1. 普通替换.replace(old,new,(max))：使用new替换old，可以指定替换最大次数 2. 映射替换（可以进行简单加密）.maketrans(“原始数据”,”需要替换的数据”)：生成一个映射表（ASCII） ！！！生成映射表的时候，两个字符串的长度必须相等，否则报错 .translate()：翻译，通过映射表将指定的字符串中的字符替换]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2和Python3的区别]]></title>
    <url>%2F2019%2F08%2F05%2FPython2%E5%92%8CPython3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1. 性能：py3其实比py2的效率低，py3有极大地优化了空间，效率处于追赶状态2. 编码：py3使用utf-8编码，使得变量名更加广阔【可以使用中文作为变量】3. 语法： ​ 去除了不等于号&lt;&gt;，py3使用的是 != ​ 加入了with…as关键字，新增了None，True，False ​ 加入了nonlocal语句 ​ 去除了print操作符，新增了print()函数 ​ 去除了raw_input操作符，加入了input()函数 ​ 新的super()函数，可以不用传参 ​ 新的八进制的字面量：py2中使用数字0表示八进制，py3中使用0o表示八进制 4. 字符和字符串​ py2中采用8-bit字符串存储，py3中采用16-bit，Unicode字符串存储 ​ py3中不管时一个字符，还是多个字符，都是字符串表示 5. 数据类型​ py2中数字类型分为int和long(长整型) ​ py3中数字类型只有一种int，新增了一种bytes【实现了字符串的编码encode和解码decode】 6. 异常​ py2中：try…except 错误表示码,变量 ​ py3中：try…except 错误表示码 as 变量： 7. 其他​ 1. py2中求变量使用xrange()，py3中使用range() ​ 2. 打开文件： ​ py2中打开文件需要两步：1.file(path) 2.poen(path) ​ py3中打开文件只需要一步：open(path)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构化查询语言]]></title>
    <url>%2F2019%2F08%2F04%2F2019-08-04%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[一：数据查询语言（DQL:Data Query Language）：​ 其语句，也称为“数据检索语句”，用以从表中获得数据，确定数据怎样在应用程序给出。保留字SELECT是DQL（也是所有SQL）用得最多的动词，其他DQL常用的保留字有WHERE，ORDER BY，GROUP BY和HAVING。这些DQL保留字常与其他类型的SQL语句一起使用。 二：数据操作语言（DML：Data Manipulation Language）：​ 其语句包括动词INSERT，UPDATE和DELETE。它们分别用于添加，修改和删除表中的行。也称为动作查询语言。 三：事务处理语言（TPL）：​ 它的语句能确保被DML语句影响的表的所有行及时得以更新。TPL语句包括BEGIN TRANSACTION，COMMIT和ROLLBACK。 四：数据控制语言（DCL）：​ 它的语句通过GRANT或REVOKE获得许可，确定单个用户和用户组对数据库对象的访问。某些RDBMS可用GRANT或REVOKE控制对表单个列的访问。 五：数据定义语言（DDL）：​ 其语句包括动词CREATE和DROP。在数据库中创建新表或删除表（CREAT TABLE 或 DROP TABLE）；为表加入索引等。DDL包括许多与人数据库目录中获得数据有关的保留字。它也是动作查询的一部分。 六：指针控制语言（CCL）：​ 它的语句，像DECLARE CURSOR，FETCH INTO和UPDATE WHERE CURRENT用于对一个或多个表单独行的操作。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
