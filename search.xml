<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[请输入密码，查看文章！( 。＿ 。) ✎ ＿ Incorrect Password! No content to display! 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]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy与scrapy-redis]]></title>
    <url>%2F2019%2F09%2F12%2Fscrapy%E4%B8%8Escrapy-redis%2F</url>
    <content type="text"><![CDATA[​ 最近在工作中写了很多 scrapy_redis 分布式爬虫，但是回想 scrapy 与 scrapy_redis 两者区别的时候，竟然，思维只是局限在了应用方面，于是乎，搜索了很多相关文章介绍，这才搞懂内部实现的原理。 首先我们从整体上来讲​ scrapy是一个Python爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。而scrapy-redis一套基于redis数据库、运行在scrapy框架之上的组件，可以让scrapy支持分布式策略，Slaver端共享Master端redis数据库里的item队列、请求队列和请求指纹集合。而为什么选择redis数据库，是因为redis支持主从同步，而且数据都是缓存在内存中的，所以基于redis的分布式爬虫，对请求和数据的高频读取效率非常高。 ​ 有一篇文章是这么说的：scrapy-redis 与 Scrapy的关系就像电脑与固态硬盘一样，是电脑中的一个插件，能让电脑更快的运行。 Scrapy 是一个爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，它可以让爬虫跑的更快。 ​ 说的一点都对，Scrapy 是一个通用的爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，为了更方便地实现Scrapy分布式爬取，而提供了一些以redis为基础的组件(仅有组件)，它可以让爬虫跑的更快。 然后介绍 scrapy 框架的运行流程及原理 ​ scrapy作为一款优秀的爬虫框架，在爬虫方面有这众多的优点。能快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。 为了方便理解，我找到了一张这样的图片： 解释说明：1、从优先级队列中获取request对象，交给engine 2、engine将request对象交给下载器下载，期间会通过downloadmiddleware的process_request方法 3、下载器完成下载，获得response对象，将该对象交给engine，期间会经过downloadmiddleware的process_response（ ）方法 4、engine将获得的response对象交给spider进行解析，期间会经过spidermiddleware的process_spider_input()的方法 5、spider解析下载器下下来的response，返回item或是links(url) 6、item或者link经过spidermiddleware的process_spider_out( )方法，交给engine 7、engine将item交给item pipeline ，将links交给调度器 8、在调度器中，先将requests对象利用scrapy内置的指纹函数生成一个指纹 9、如果requests对象中的don’t filter参数设置为False，并且该requests对象的指纹不在信息指纹的队列中，那么就把该request对象放到优先级队列中 循环以上操作 中间件主要存在两个地方，从图片当中我们可以看到： spider 与 engine 之间（爬虫中间件）： ​ 介于Scrapy引擎和爬虫之间的框架，主要工作是处理爬虫的响应输入和请求输出 download 与 engine 之间（下载器中间件） ： 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应 借此机会，我们结合程序，解析一下框架中的 middleware.py ： Spider Middleware有以下几个函数被管理: process_spider_input 接收一个response对象并处理, 位置是Downloader–&gt;process_spider_input–&gt;Spiders(Downloader和Spiders是scrapy官方结构图中的组件) ​ - process_spider_exception spider出现的异常时被调用 - process_spider_output 当Spider处理response返回result时,该方法被调用 - process_start_requests 当spider发出请求时,被调用 Downloader Middleware有以下几个函数被管理 - process_request request通过下载中间件时，该方法被调用，这里可以设置代理，设置request.meta[‘proxy’] 就行 - process_response 下载结果经过中间件时被此方法处理 - process_exception 下载过程中出现异常时被调用 个人理解scrapy的优缺点：优点：scrapy 是异步的，写middleware,方便写一些统一的过滤器 缺点：基于python的爬虫框架，扩展性比较差，基于twisted框架，运行中的exception是不会干掉reactor，并且异步框架出错后是不会停掉其他任务的，数据出错后难以察觉。 scrapy_redis分布式爬虫最后回到我们这篇文章的重点（敲黑板…） Scrapy-redis提供了下面四种组件（components）：(四种组件意味着这四个模块都要做相应的修改) Scheduler： Scrapy改造了python本来的collection.deque(双向队列)形成了自己的Scrapy queue，但是Scrapy多个spider不能共享待爬取队列Scrapy queue， 即Scrapy本身不支持爬虫分布式，scrapy-redis 的解决是把这个Scrapy queue换成redis数据库（也是指redis队列），从同一个redis-server存放要爬取的request，便能让多个spider去同一个数据库里读取。 Scrapy中跟“待爬队列”直接相关的就是调度器Scheduler，它负责对新的request进行入列操作（加入Scrapy queue），取出下一个要爬取的request（从Scrapy queue中取出）等操作。它把待爬队列按照优先级建立了一个字典结构，然后根据request中的优先级，来决定该入哪个队列，出列时则按优先级较小的优先出列。为了管理这个比较高级的队列字典，Scheduler需要提供一系列的方法。但是原来的Scheduler已经无法使用，所以使用Scrapy-redis的scheduler组件。 Duplication Filter： Scrapy中用集合实现这个request去重功能，Scrapy中把已经发送的request指纹放入到一个集合中，把下一个request的指纹拿到集合中比对，如果该指纹存在于集合中，说明这个request发送过了，如果没有则继续操作。 在scrapy-redis中去重是由Duplication Filter组件来实现的，它通过redis的set 不重复的特性，巧妙的实现了Duplication Filter去重。scrapy-redis调度器从引擎接受request，将request的指纹存⼊redis的set检查是否重复，并将不重复的request push写⼊redis的 request queue。 引擎请求request(Spider发出的）时，调度器从redis的request queue队列⾥里根据优先级pop 出⼀个request 返回给引擎，引擎将此request发给spider处理。 Item Pipeline： 引擎将(Spider返回的)爬取到的Item给Item Pipeline，scrapy-redis 的Item Pipeline将爬取到的 Item 存⼊redis的 items queue。 修改过Item Pipeline可以很方便的根据 key 从 items queue 提取item，从⽽实现items processes集群。 Base Spider： 不在使用scrapy原有的Spider类，重写的RedisSpider继承了Spider和RedisMixin这两个类，RedisMixin是用来从redis读取url的类。 当我们生成一个Spider继承RedisSpider时，调用setup_redis函数，这个函数会去连接redis数据库，然后会设置signals(信号)： 一个是当spider空闲时候的signal，会调用spider_idle函数，这个函数调用schedule_next_request函数，保证spider是一直活着的状态，并且抛出DontCloseSpider异常。一个是当抓到一个item时的signal，会调用item_scraped函数，这个函数会调用schedule_next_request函数，获取下一个request。 Scrapy-redis架构： 如上图所示，我们可以发现，scrapy-redis在scrapy的架构上增加了redis，与scrapy相差无几。本质的区别就是，将scrapy的内置的去重的队列和待抓取的request队列换成了redis的集合。就这一个小小的改动，就使得了scrapy-redis支持了分布式抓取。 Scrapy-Redis分布式策略： 假设有四台电脑：Windows 10、Mac OS X、Ubuntu 16.04、CentOS 7.2，任意一台电脑都可以作为 Master端 或 Slaver端，比如： –Master端(核心服务器) ：使用 Windows 10，搭建一个Redis数据库，不负责爬取，只负责url指纹判重、Request的分配，以及数据的存储–Slaver端(爬虫程序执行端) ：使用 Mac OS X 、Ubuntu 16.04、CentOS 7.2，负责执行爬虫程序，运行过程中提交新的Request给Master 首先Slaver端从Master端拿任务（Request、url）进行数据抓取，Slaver抓取数据的同时，产生新任务的Request便提交给 Master 处理；Master端只有一个Redis数据库，负责将未处理的Request去重和任务分配，将处理后的Request加入待爬队列，并且存储爬取的数据。 明白了原理之后我们就要入手程序了 Scrapy-Redis默认使用的就是这种策略，我们实现起来很简单，因为任务调度等工作Scrapy-Redis都已经帮我们做好了，我们只需要继承RedisSpider、指定redis_key就行了。 将 scrapy 变成 scrapy-redis 的过程（前提是pip install scrapy-redis） 1、修改settings.py文件，最简单的方式是使用redis替换机器内存，你只需要在 settings.py 中加上三代码，就能让你的爬虫变为分布式。 2、配置redis 3、配置如下参数 4、自定义爬虫类继承RedisSpider 如果你现在运行你的爬虫，你可以在redis中看到出现了这两个key: 格式是set，即不会有重复数据。前者就是redis的去重队列，对应DUPEFILTER_CLASS，后者是redis的请求调度，把里面的请求分发给爬虫，对应SCHEDULER。（里面的数据不会自动删除，如果你第二次跑，需要提前清空里面的数据） 备注：虽然scrapy_redis 可以极大的提高爬虫的运行的效率，但也是存在缺点的，Scrapy-Redis调度的任务是Request对象，里面信息量比较大（不仅包含url，还有callback函数、headers等信息），可能导致的结果就是会降低爬虫速度、而且会占用Redis大量的存储空间，所以如果要保证效率，那么就需要一定硬件水平。最后提醒一下大家，并不是所有的网站都可以采用分布式爬虫进行采集，爬虫要追求灵活，所以scrapy-redis并不能代替传统的request爬虫。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本山大叔-念诗之王]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%9C%AC%E5%B1%B1%E5%A4%A7%E5%8F%94-%E5%BF%B5%E8%AF%97%E4%B9%8B%E7%8E%8B%2F</url>
    <content type="text"><![CDATA[中国 Rap 之王]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>bilibili</tag>
        <tag>鬼畜</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[某科学的超电磁炮]]></title>
    <url>%2F2019%2F08%2F10%2F%E8%B6%85%E7%94%B5%E7%A3%81%E7%82%AE%2F</url>
    <content type="text"><![CDATA[B站剪辑xsjhitokoto() 插件暂时不能使用，忽略......]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建单例]]></title>
    <url>%2F2019%2F08%2F10%2F%E5%88%9B%E5%BB%BA%E5%8D%95%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[使用装饰器： 装饰器不但可以装饰函数，也可以装饰类 如果要书写单例，命名为：defaultInstance，currentInstance，getInstance等 思路：​ 在外部函数中定义一个变量，在内部函数中进行单例的设置，最终将设置的结果返回 方式一1234567891011121314151617181920def singleton(cls): instance = None def getInstance(*args,**kwargs): nonlocal instance #局部变量和全局变量重名，扩大作用域 if not instance: instance = cls(*args,**kwargs) return instance return getInstance@singletonclass Check(): def __init__(self,name,age): self.name = name self.age = agec1 = Check("jack",10)print(c1)c2 = Check("abc",45)print(c2) 方式二123456789101112131415161718192021222324252627282930313233def singleton(cls): #定义一个字典，字典用来保存被装饰的类和对应的唯一的对象,&#123;类:对象&#125; instanceDict = &#123;&#125; def getInstance(*args,**kwargs): if cls not in instanceDict: instanceDict[cls] = cls(*args,**kwargs) return instanceDict[cls] return getInstance@singletonclass Person(object): #实例属性 def __init__(self,name): self.name = name #成员函数 def show(self): pass #类方法 @classmethod def func(cls): pass #静态方法 @staticmethod def func2(): passp1 = Person()print(p1)p2 = Person()print(p2)p1.show()p1.func() 单例类和普通类的区别仅仅是单例类只能创建一个对象，其余的用法和普通类完全相同]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python字符串功能]]></title>
    <url>%2F2019%2F08%2F06%2FPython%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[字符串功能填充.center(width,fillchar)：被填充字符长度只能为 1 .ljust(width,fillchar)：原字符串被居左，其他剩余的字符串使用指定的字符填充，默认使用空格填充 .rjust(width,fillchar)：居右 .zfill(width)：返回一个长度为width的字符串，原字符串右对齐，前面补0 .count((str)[,start],[,end])：返回字符串中str出现的次数，可以指定一个范围，默认从头到尾 查找.find((str)[,start],[,end])：检测str字符串中是否包含在字符串中，可以指定范围，默认从头到尾，得到的是第一次出现的下标，没有找到则返回 -1 .rfind：从右到左 .index()：从列表中获取第一个匹配元素的位置，前提时该元素存在 .rindex()：从右往左 字母转换eval()：可以进行内部数字运算 .lower()：字母全部小写 .upper()：字母全部大写 .swapcase()：字母大转小，小转大 .title()：每个首字母大写 .capitalize()：第一个单词首字母大写 chr(xx) ：char actor ， 字符， 将整数转化为在ASCii码中对应的字符 ord(xx) ：ordinary ，原始的，将资格字符转化为ASCII码中对应的数字 提取.strip：截掉左，右两侧指定字符串，默认为空格 .lstrip：截掉左侧指定字符串，默认为空格 .strip：截掉右侧指定字符串，默认为空格 数字进制转换int(“ “)：将x转化为十进制 int 中的 base 关键字表示按当前需要被转换的数据的形式【什么进制 】，最终通过int返回的是十进制 bin( )：将x转化为二进制hex( )：将x转化为十六进制 cot( )：将x转化为八进制 字符串的分割，列表的合并list = str.split(substr,num)：substr表示分隔符，num表示分割的最大次数 “ substr “.join(列表)：将一个列表中的元素转化为字符串 替换1. 普通替换.replace(old,new,(max))：使用new替换old，可以指定替换最大次数 2. 映射替换（可以进行简单加密）.maketrans(“原始数据”,”需要替换的数据”)：生成一个映射表（ASCII） ！！！生成映射表的时候，两个字符串的长度必须相等，否则报错 .translate()：翻译，通过映射表将指定的字符串中的字符替换]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2和Python3的区别]]></title>
    <url>%2F2019%2F08%2F05%2FPython2%E5%92%8CPython3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1. 性能：py3其实比py2的效率低，py3有极大地优化了空间，效率处于追赶状态2. 编码：py3使用utf-8编码，使得变量名更加广阔【可以使用中文作为变量】3. 语法： ​ 去除了不等于号&lt;&gt;，py3使用的是 != ​ 加入了with…as关键字，新增了None，True，False ​ 加入了nonlocal语句 ​ 去除了print操作符，新增了print()函数 ​ 去除了raw_input操作符，加入了input()函数 ​ 新的super()函数，可以不用传参 ​ 新的八进制的字面量：py2中使用数字0表示八进制，py3中使用0o表示八进制 4. 字符和字符串​ py2中采用8-bit字符串存储，py3中采用16-bit，Unicode字符串存储 ​ py3中不管时一个字符，还是多个字符，都是字符串表示 5. 数据类型​ py2中数字类型分为int和long(长整型) ​ py3中数字类型只有一种int，新增了一种bytes【实现了字符串的编码encode和解码decode】 6. 异常​ py2中：try…except 错误表示码,变量 ​ py3中：try…except 错误表示码 as 变量： 7. 其他​ 1. py2中求变量使用xrange()，py3中使用range() ​ 2. 打开文件： ​ py2中打开文件需要两步：1.file(path) 2.poen(path) ​ py3中打开文件只需要一步：open(path)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构化查询语言]]></title>
    <url>%2F2019%2F08%2F04%2F2019-08-04%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[一：数据查询语言（DQL:Data Query Language）：​ 其语句，也称为“数据检索语句”，用以从表中获得数据，确定数据怎样在应用程序给出。保留字SELECT是DQL（也是所有SQL）用得最多的动词，其他DQL常用的保留字有WHERE，ORDER BY，GROUP BY和HAVING。这些DQL保留字常与其他类型的SQL语句一起使用。 二：数据操作语言（DML：Data Manipulation Language）：​ 其语句包括动词INSERT，UPDATE和DELETE。它们分别用于添加，修改和删除表中的行。也称为动作查询语言。 三：事务处理语言（TPL）：​ 它的语句能确保被DML语句影响的表的所有行及时得以更新。TPL语句包括BEGIN TRANSACTION，COMMIT和ROLLBACK。 四：数据控制语言（DCL）：​ 它的语句通过GRANT或REVOKE获得许可，确定单个用户和用户组对数据库对象的访问。某些RDBMS可用GRANT或REVOKE控制对表单个列的访问。 五：数据定义语言（DDL）：​ 其语句包括动词CREATE和DROP。在数据库中创建新表或删除表（CREAT TABLE 或 DROP TABLE）；为表加入索引等。DDL包括许多与人数据库目录中获得数据有关的保留字。它也是动作查询的一部分。 六：指针控制语言（CCL）：​ 它的语句，像DECLARE CURSOR，FETCH INTO和UPDATE WHERE CURRENT用于对一个或多个表单独行的操作。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
