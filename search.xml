<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[请输入密码，查看文章！( 。＿ 。) ✎ ＿ Incorrect Password! No content to display! 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]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy与scrapy-redis]]></title>
    <url>%2F2019%2F09%2F12%2Fscrapy%E4%B8%8Escrapy-redis%2F</url>
    <content type="text"><![CDATA[​ 最近在工作中写了很多 scrapy_redis 分布式爬虫，但是回想 scrapy 与 scrapy_redis 两者区别的时候，竟然，思维只是局限在了应用方面，于是乎，搜索了很多相关文章介绍，这才搞懂内部实现的原理。 首先我们从整体上来讲​ scrapy是一个Python爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。而scrapy-redis一套基于redis数据库、运行在scrapy框架之上的组件，可以让scrapy支持分布式策略，Slaver端共享Master端redis数据库里的item队列、请求队列和请求指纹集合。而为什么选择redis数据库，是因为redis支持主从同步，而且数据都是缓存在内存中的，所以基于redis的分布式爬虫，对请求和数据的高频读取效率非常高。 ​ 有一篇文章是这么说的：scrapy-redis 与 Scrapy的关系就像电脑与固态硬盘一样，是电脑中的一个插件，能让电脑更快的运行。 Scrapy 是一个爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，它可以让爬虫跑的更快。 ​ 说的一点都对，Scrapy 是一个通用的爬虫框架，scrapy-redis 则是这个框架上可以选择的插件，为了更方便地实现Scrapy分布式爬取，而提供了一些以redis为基础的组件(仅有组件)，它可以让爬虫跑的更快。 然后介绍 scrapy 框架的运行流程及原理 ​ scrapy作为一款优秀的爬虫框架，在爬虫方面有这众多的优点。能快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。 为了方便理解，我找到了一张这样的图片： 解释说明：1、从优先级队列中获取request对象，交给engine 2、engine将request对象交给下载器下载，期间会通过downloadmiddleware的process_request方法 3、下载器完成下载，获得response对象，将该对象交给engine，期间会经过downloadmiddleware的process_response（ ）方法 4、engine将获得的response对象交给spider进行解析，期间会经过spidermiddleware的process_spider_input()的方法 5、spider解析下载器下下来的response，返回item或是links(url) 6、item或者link经过spidermiddleware的process_spider_out( )方法，交给engine 7、engine将item交给item pipeline ，将links交给调度器 8、在调度器中，先将requests对象利用scrapy内置的指纹函数生成一个指纹 9、如果requests对象中的don’t filter参数设置为False，并且该requests对象的指纹不在信息指纹的队列中，那么就把该request对象放到优先级队列中 循环以上操作 中间件主要存在两个地方，从图片当中我们可以看到： spider 与 engine 之间（爬虫中间件）： ​ 介于Scrapy引擎和爬虫之间的框架，主要工作是处理爬虫的响应输入和请求输出 download 与 engine 之间（下载器中间件） ： 位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应 借此机会，我们结合程序，解析一下框架中的 middleware.py ： Spider Middleware有以下几个函数被管理: process_spider_input 接收一个response对象并处理, 位置是Downloader–&gt;process_spider_input–&gt;Spiders(Downloader和Spiders是scrapy官方结构图中的组件) ​ - process_spider_exception spider出现的异常时被调用 - process_spider_output 当Spider处理response返回result时,该方法被调用 - process_start_requests 当spider发出请求时,被调用 Downloader Middleware有以下几个函数被管理 - process_request request通过下载中间件时，该方法被调用，这里可以设置代理，设置request.meta[‘proxy’] 就行 - process_response 下载结果经过中间件时被此方法处理 - process_exception 下载过程中出现异常时被调用 个人理解scrapy的优缺点：优点：scrapy 是异步的，写middleware,方便写一些统一的过滤器 缺点：基于python的爬虫框架，扩展性比较差，基于twisted框架，运行中的exception是不会干掉reactor，并且异步框架出错后是不会停掉其他任务的，数据出错后难以察觉。 scrapy_redis分布式爬虫最后回到我们这篇文章的重点（敲黑板…） Scrapy-redis提供了下面四种组件（components）：(四种组件意味着这四个模块都要做相应的修改) Scheduler： Scrapy改造了python本来的collection.deque(双向队列)形成了自己的Scrapy queue，但是Scrapy多个spider不能共享待爬取队列Scrapy queue， 即Scrapy本身不支持爬虫分布式，scrapy-redis 的解决是把这个Scrapy queue换成redis数据库（也是指redis队列），从同一个redis-server存放要爬取的request，便能让多个spider去同一个数据库里读取。 Scrapy中跟“待爬队列”直接相关的就是调度器Scheduler，它负责对新的request进行入列操作（加入Scrapy queue），取出下一个要爬取的request（从Scrapy queue中取出）等操作。它把待爬队列按照优先级建立了一个字典结构，然后根据request中的优先级，来决定该入哪个队列，出列时则按优先级较小的优先出列。为了管理这个比较高级的队列字典，Scheduler需要提供一系列的方法。但是原来的Scheduler已经无法使用，所以使用Scrapy-redis的scheduler组件。 Duplication Filter： Scrapy中用集合实现这个request去重功能，Scrapy中把已经发送的request指纹放入到一个集合中，把下一个request的指纹拿到集合中比对，如果该指纹存在于集合中，说明这个request发送过了，如果没有则继续操作。 在scrapy-redis中去重是由Duplication Filter组件来实现的，它通过redis的set 不重复的特性，巧妙的实现了Duplication Filter去重。scrapy-redis调度器从引擎接受request，将request的指纹存⼊redis的set检查是否重复，并将不重复的request push写⼊redis的 request queue。 引擎请求request(Spider发出的）时，调度器从redis的request queue队列⾥里根据优先级pop 出⼀个request 返回给引擎，引擎将此request发给spider处理。 Item Pipeline： 引擎将(Spider返回的)爬取到的Item给Item Pipeline，scrapy-redis 的Item Pipeline将爬取到的 Item 存⼊redis的 items queue。 修改过Item Pipeline可以很方便的根据 key 从 items queue 提取item，从⽽实现items processes集群。 Base Spider： 不在使用scrapy原有的Spider类，重写的RedisSpider继承了Spider和RedisMixin这两个类，RedisMixin是用来从redis读取url的类。 当我们生成一个Spider继承RedisSpider时，调用setup_redis函数，这个函数会去连接redis数据库，然后会设置signals(信号)： 一个是当spider空闲时候的signal，会调用spider_idle函数，这个函数调用schedule_next_request函数，保证spider是一直活着的状态，并且抛出DontCloseSpider异常。一个是当抓到一个item时的signal，会调用item_scraped函数，这个函数会调用schedule_next_request函数，获取下一个request。 Scrapy-redis架构： 如上图所示，我们可以发现，scrapy-redis在scrapy的架构上增加了redis，与scrapy相差无几。本质的区别就是，将scrapy的内置的去重的队列和待抓取的request队列换成了redis的集合。就这一个小小的改动，就使得了scrapy-redis支持了分布式抓取。 Scrapy-Redis分布式策略： 假设有四台电脑：Windows 10、Mac OS X、Ubuntu 16.04、CentOS 7.2，任意一台电脑都可以作为 Master端 或 Slaver端，比如： –Master端(核心服务器) ：使用 Windows 10，搭建一个Redis数据库，不负责爬取，只负责url指纹判重、Request的分配，以及数据的存储–Slaver端(爬虫程序执行端) ：使用 Mac OS X 、Ubuntu 16.04、CentOS 7.2，负责执行爬虫程序，运行过程中提交新的Request给Master 首先Slaver端从Master端拿任务（Request、url）进行数据抓取，Slaver抓取数据的同时，产生新任务的Request便提交给 Master 处理；Master端只有一个Redis数据库，负责将未处理的Request去重和任务分配，将处理后的Request加入待爬队列，并且存储爬取的数据。 明白了原理之后我们就要入手程序了 Scrapy-Redis默认使用的就是这种策略，我们实现起来很简单，因为任务调度等工作Scrapy-Redis都已经帮我们做好了，我们只需要继承RedisSpider、指定redis_key就行了。 将 scrapy 变成 scrapy-redis 的过程（前提是pip install scrapy-redis） 1、修改settings.py文件，最简单的方式是使用redis替换机器内存，你只需要在 settings.py 中加上三代码，就能让你的爬虫变为分布式。 2、配置redis 3、配置如下参数 4、自定义爬虫类继承RedisSpider 如果你现在运行你的爬虫，你可以在redis中看到出现了这两个key: 格式是set，即不会有重复数据。前者就是redis的去重队列，对应DUPEFILTER_CLASS，后者是redis的请求调度，把里面的请求分发给爬虫，对应SCHEDULER。（里面的数据不会自动删除，如果你第二次跑，需要提前清空里面的数据） 备注：虽然scrapy_redis 可以极大的提高爬虫的运行的效率，但也是存在缺点的，Scrapy-Redis调度的任务是Request对象，里面信息量比较大（不仅包含url，还有callback函数、headers等信息），可能导致的结果就是会降低爬虫速度、而且会占用Redis大量的存储空间，所以如果要保证效率，那么就需要一定硬件水平。最后提醒一下大家，并不是所有的网站都可以采用分布式爬虫进行采集，爬虫要追求灵活，所以scrapy-redis并不能代替传统的request爬虫。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本山大叔-念诗之王]]></title>
    <url>%2F2019%2F08%2F16%2F%E6%9C%AC%E5%B1%B1%E5%A4%A7%E5%8F%94-%E5%BF%B5%E8%AF%97%E4%B9%8B%E7%8E%8B%2F</url>
    <content type="text"><![CDATA[中国 Rap 之王]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>鬼畜</tag>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[某科学的超电磁炮]]></title>
    <url>%2F2019%2F08%2F10%2F%E8%B6%85%E7%94%B5%E7%A3%81%E7%82%AE%2F</url>
    <content type="text"><![CDATA[B站剪辑xsjhitokoto() 插件暂时不能使用，忽略......]]></content>
      <categories>
        <category>bilibili</category>
      </categories>
      <tags>
        <tag>bilibili</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建单例]]></title>
    <url>%2F2019%2F08%2F10%2F%E5%88%9B%E5%BB%BA%E5%8D%95%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[使用装饰器： 装饰器不但可以装饰函数，也可以装饰类 如果要书写单例，命名为：defaultInstance，currentInstance，getInstance等 思路：​ 在外部函数中定义一个变量，在内部函数中进行单例的设置，最终将设置的结果返回 方式一1234567891011121314151617181920def singleton(cls): instance = None def getInstance(*args,**kwargs): nonlocal instance #局部变量和全局变量重名，扩大作用域 if not instance: instance = cls(*args,**kwargs) return instance return getInstance@singletonclass Check(): def __init__(self,name,age): self.name = name self.age = agec1 = Check("jack",10)print(c1)c2 = Check("abc",45)print(c2) 方式二123456789101112131415161718192021222324252627282930313233def singleton(cls): #定义一个字典，字典用来保存被装饰的类和对应的唯一的对象,&#123;类:对象&#125; instanceDict = &#123;&#125; def getInstance(*args,**kwargs): if cls not in instanceDict: instanceDict[cls] = cls(*args,**kwargs) return instanceDict[cls] return getInstance@singletonclass Person(object): #实例属性 def __init__(self,name): self.name = name #成员函数 def show(self): pass #类方法 @classmethod def func(cls): pass #静态方法 @staticmethod def func2(): passp1 = Person()print(p1)p2 = Person()print(p2)p1.show()p1.func() 单例类和普通类的区别仅仅是单例类只能创建一个对象，其余的用法和普通类完全相同]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python字符串功能]]></title>
    <url>%2F2019%2F08%2F06%2FPython%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[字符串功能填充.center(width,fillchar)：被填充字符长度只能为 1 .ljust(width,fillchar)：原字符串被居左，其他剩余的字符串使用指定的字符填充，默认使用空格填充 .rjust(width,fillchar)：居右 .zfill(width)：返回一个长度为width的字符串，原字符串右对齐，前面补0 .count((str)[,start],[,end])：返回字符串中str出现的次数，可以指定一个范围，默认从头到尾 查找.find((str)[,start],[,end])：检测str字符串中是否包含在字符串中，可以指定范围，默认从头到尾，得到的是第一次出现的下标，没有找到则返回 -1 .rfind：从右到左 .index()：从列表中获取第一个匹配元素的位置，前提时该元素存在 .rindex()：从右往左 字母转换eval()：可以进行内部数字运算 .lower()：字母全部小写 .upper()：字母全部大写 .swapcase()：字母大转小，小转大 .title()：每个首字母大写 .capitalize()：第一个单词首字母大写 chr(xx) ：char actor ， 字符， 将整数转化为在ASCii码中对应的字符 ord(xx) ：ordinary ，原始的，将资格字符转化为ASCII码中对应的数字 提取.strip：截掉左，右两侧指定字符串，默认为空格 .lstrip：截掉左侧指定字符串，默认为空格 .strip：截掉右侧指定字符串，默认为空格 数字进制转换int(“ “)：将x转化为十进制 int 中的 base 关键字表示按当前需要被转换的数据的形式【什么进制 】，最终通过int返回的是十进制 bin( )：将x转化为二进制hex( )：将x转化为十六进制 cot( )：将x转化为八进制 字符串的分割，列表的合并list = str.split(substr,num)：substr表示分隔符，num表示分割的最大次数 “ substr “.join(列表)：将一个列表中的元素转化为字符串 替换1. 普通替换.replace(old,new,(max))：使用new替换old，可以指定替换最大次数 2. 映射替换（可以进行简单加密）.maketrans(“原始数据”,”需要替换的数据”)：生成一个映射表（ASCII） ！！！生成映射表的时候，两个字符串的长度必须相等，否则报错 .translate()：翻译，通过映射表将指定的字符串中的字符替换]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python2和Python3的区别]]></title>
    <url>%2F2019%2F08%2F05%2FPython2%E5%92%8CPython3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[1. 性能：py3其实比py2的效率低，py3有极大地优化了空间，效率处于追赶状态2. 编码：py3使用utf-8编码，使得变量名更加广阔【可以使用中文作为变量】3. 语法： ​ 去除了不等于号&lt;&gt;，py3使用的是 != ​ 加入了with…as关键字，新增了None，True，False ​ 加入了nonlocal语句 ​ 去除了print操作符，新增了print()函数 ​ 去除了raw_input操作符，加入了input()函数 ​ 新的super()函数，可以不用传参 ​ 新的八进制的字面量：py2中使用数字0表示八进制，py3中使用0o表示八进制 4. 字符和字符串​ py2中采用8-bit字符串存储，py3中采用16-bit，Unicode字符串存储 ​ py3中不管时一个字符，还是多个字符，都是字符串表示 5. 数据类型​ py2中数字类型分为int和long(长整型) ​ py3中数字类型只有一种int，新增了一种bytes【实现了字符串的编码encode和解码decode】 6. 异常​ py2中：try…except 错误表示码,变量 ​ py3中：try…except 错误表示码 as 变量： 7. 其他​ 1. py2中求变量使用xrange()，py3中使用range() ​ 2. 打开文件： ​ py2中打开文件需要两步：1.file(path) 2.poen(path) ​ py3中打开文件只需要一步：open(path)]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构化查询语言]]></title>
    <url>%2F2019%2F08%2F04%2F2019-08-04%E7%BB%93%E6%9E%84%E5%8C%96%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80%2F</url>
    <content type="text"><![CDATA[一：数据查询语言（DQL:Data Query Language）：​ 其语句，也称为“数据检索语句”，用以从表中获得数据，确定数据怎样在应用程序给出。保留字SELECT是DQL（也是所有SQL）用得最多的动词，其他DQL常用的保留字有WHERE，ORDER BY，GROUP BY和HAVING。这些DQL保留字常与其他类型的SQL语句一起使用。 二：数据操作语言（DML：Data Manipulation Language）：​ 其语句包括动词INSERT，UPDATE和DELETE。它们分别用于添加，修改和删除表中的行。也称为动作查询语言。 三：事务处理语言（TPL）：​ 它的语句能确保被DML语句影响的表的所有行及时得以更新。TPL语句包括BEGIN TRANSACTION，COMMIT和ROLLBACK。 四：数据控制语言（DCL）：​ 它的语句通过GRANT或REVOKE获得许可，确定单个用户和用户组对数据库对象的访问。某些RDBMS可用GRANT或REVOKE控制对表单个列的访问。 五：数据定义语言（DDL）：​ 其语句包括动词CREATE和DROP。在数据库中创建新表或删除表（CREAT TABLE 或 DROP TABLE）；为表加入索引等。DDL包括许多与人数据库目录中获得数据有关的保留字。它也是动作查询的一部分。 六：指针控制语言（CCL）：​ 它的语句，像DECLARE CURSOR，FETCH INTO和UPDATE WHERE CURRENT用于对一个或多个表单独行的操作。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
</search>
